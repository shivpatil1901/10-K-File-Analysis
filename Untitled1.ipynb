{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Installing the necessary libraries"
      ],
      "metadata": {
        "id": "X5prhldx-aP_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQy6KI1-jijE"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install panda\n",
        "!pip install json\n",
        "!pip install ocr-nanonets-wrapper\n",
        "!pip install langchain\n",
        "!pip install langchain_community\n",
        "# !pip install ctransformers\n",
        "!pip install sentence-transformers\n",
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import streamlit as st\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain.retrievers import EnsembleRetriever\n",
        "from langchain.docstore.document import Document\n",
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from langchain_community.document_loaders import DataFrameLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.llms import CTransformers\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from nanonets import NANONETSOCR"
      ],
      "metadata": {
        "id": "0BviHc-xj8Lc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import CTransformers"
      ],
      "metadata": {
        "id": "gewbDJUlr-Xr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hugging Face Authentication"
      ],
      "metadata": {
        "id": "cMopU21OAbj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C-ljERfp1tU",
        "outputId": "2c7388d5-19d7-4975-9631-ba47300fc148"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HuggingFace authentication Token and Imports"
      ],
      "metadata": {
        "id": "XsgeT4XKqDV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-llms-huggingface"
      ],
      "metadata": {
        "id": "XoA2kpxDrUhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "huggingFaceToken='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'"
      ],
      "metadata": {
        "id": "ET-c7Ea4qDBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "File Path being used for RAG"
      ],
      "metadata": {
        "id": "4qgrAf4k_VF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path='full-submission.txt'\n",
        "# DB_FAISS_PATH = \"vectorstore/vector_db\""
      ],
      "metadata": {
        "id": "Hh0PZfkfkk53"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig,AutoModel\n"
      ],
      "metadata": {
        "id": "mAo7-bte0Rxp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "fIeqehMn2bOr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "db_faiss_path = os.path.join(tempfile.mkdtemp(), 'faiss_index.index')\n",
        "embeddings_path = os.path.join(tempfile.mkdtemp(), 'embeddings_path')"
      ],
      "metadata": {
        "id": "EAszax_x4qJk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_text_file(file_path):\n",
        "    \"\"\"\n",
        "    Load text file and return its content as a single string.\n",
        "    \"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        content = file.read()\n",
        "    return content\n",
        "import faiss\n",
        "\n",
        "def create_embeddings_and_save(file_path, db_faiss_path,embeddings_path):\n",
        "    \"\"\"\n",
        "    Load and process a document, create embeddings from its text chunks, and save them into the FAISS knowledge base.\n",
        "    \"\"\"\n",
        "    # Load text content from the file\n",
        "    text_content = load_text_file(file_path)\n",
        "\n",
        "    # Initialize text splitter\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "\n",
        "    # Split the text content into chunks\n",
        "    splits = text_splitter.split_text(text_content)\n",
        "\n",
        "    # Initialize the model and tokenizer\n",
        "    model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "    # Convert the text chunks into embeddings\n",
        "    chunk_embeddings = []\n",
        "    for chunk in splits:\n",
        "        encoded_input = tokenizer(chunk, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "        with torch.no_grad():\n",
        "            output = model(**encoded_input)\n",
        "        chunk_embedding = output.last_hidden_state.mean(dim=1).squeeze().detach().numpy()\n",
        "        chunk_embeddings.append(chunk_embedding)\n",
        "\n",
        "    # Initialize the FAISS index\n",
        "    d = chunk_embeddings[0].shape[0]  # Dimension of the embeddings\n",
        "    index = faiss.IndexIDMap(faiss.IndexFlatL2(d))\n",
        "\n",
        "    # # Add embeddings to the index\n",
        "    # for i, emb in enumerate(chunk_embeddings):\n",
        "    #     index.add_with_ids(emb, np.array([i]))\n",
        "\n",
        "    # # Save the index and embeddings mapping\n",
        "    # faiss.write_index(faiss_index, db_faiss_path)\n",
        "    for i, emb in enumerate(chunk_embeddings):\n",
        "        emb = emb.reshape(1, -1)  # Reshape to make it a 2-dimensional array\n",
        "        index.add_with_ids(emb, np.array([i]))\n",
        "\n",
        "    # Save the index and embeddings mapping\n",
        "    faiss.write_index(index, db_faiss_path)\n",
        "\n",
        "    np.save(embeddings_path, np.array(chunk_embeddings))\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "file_path = 'full-submission.txt'\n",
        "# db_faiss_path = DB_FAISS_PATH\n",
        "create_embeddings_and_save(file_path, db_faiss_path,embeddings_path)\n"
      ],
      "metadata": {
        "id": "lOP0xpIUmEao"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating embedding for query text"
      ],
      "metadata": {
        "id": "TaG8o_Wm9jW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def generate_embedding(text, model, tokenizer):\n",
        "    \"\"\"\n",
        "    Generate embeddings for a given text using a pre-trained transformer-based model.\n",
        "\n",
        "    Args:\n",
        "    - text (str): The input text.\n",
        "    - model: The pre-trained transformer-based model.\n",
        "    - tokenizer: The tokenizer corresponding to the model.\n",
        "\n",
        "    Returns:\n",
        "    - embedding (numpy.ndarray): The generated embedding for the input text.\n",
        "    \"\"\"\n",
        "    # Tokenize the input text\n",
        "    encoded_input = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate embeddings\n",
        "    with torch.no_grad():\n",
        "        output = model(**encoded_input)\n",
        "\n",
        "    # Take the mean of the output embeddings\n",
        "    embedding = output.last_hidden_state.mean(dim=1).squeeze().detach().numpy()\n",
        "\n",
        "    return embedding\n",
        "\n",
        "# Example usage:\n",
        "text = \"This is an example sentence.\"\n",
        "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "embedding = generate_embedding(text, model, tokenizer)\n",
        "print(\"Embedding shape:\", embedding.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aoXaiTs9jFc",
        "outputId": "02ae5331-2ba6-4c2d-982c-efdd6ce2d33d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding shape: (384,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Hugging Face LLM"
      ],
      "metadata": {
        "id": "wMrfNuHYsA5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.huggingface import HuggingFaceLLM"
      ],
      "metadata": {
        "id": "uNBXoKqftIA2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from llama_index.prompts.prompts import SimpleInputPrompt\n",
        "system_prompt = \"You are a Q&A assistant. Your goal is to answer questions as accurately as possible based on the instructions and context provided.\"\n",
        "# This will wrap the default prompts that are internal to llama-index\n",
        "query_wrapper_prompt = \"<|USER|>{query_str}<|ASSISTANT|>\""
      ],
      "metadata": {
        "id": "1ar5GShttTl2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "3nGGnzxCtWTo"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "id": "vAP_zTx3AMo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceLLM(\n",
        "    context_window=4096,\n",
        "    max_new_tokens=256,\n",
        "    generate_kwargs={\"temperature\": 0.1, \"do_sample\": True},\n",
        "    system_prompt=system_prompt,\n",
        "    query_wrapper_prompt=query_wrapper_prompt,\n",
        "    tokenizer_name=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
        "    model_name=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
        "    device_map=\"auto\",\n",
        "    tokenizer_kwargs={\"max_length\": 4096},\n",
        "    model_kwargs={\"torch_dtype\": torch.float16}\n",
        "\n",
        ")\n"
      ],
      "metadata": {
        "id": "N_-7zyxzmIvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passing Queries for analysis"
      ],
      "metadata": {
        "id": "8VjNjKJvsPkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(query, llm, faiss_index, k=5):\n",
        "    \"\"\"\n",
        "    Generate a response to the given query using the Language Learning Model (LLM).\n",
        "    Incorporates context from the top k retrieved documents in the FAISS knowledge base.\n",
        "    \"\"\"\n",
        "    # Retrieve top k documents relevant to the query\n",
        "    retrieved_docs = faiss_index.search(query, k=k)\n",
        "\n",
        "    # Extract context from retrieved documents\n",
        "    context = \"\"\n",
        "    for doc_id, _ in retrieved_docs:\n",
        "        # Assume you have a function to retrieve the document content by ID\n",
        "        doc_content = faiss_index.get_document_content(doc_id)\n",
        "        context += doc_content + \" \"  # Concatenate context from all retrieved documents\n",
        "\n",
        "    # Prepare system prompt with query and retrieved context\n",
        "    system_prompt = f\"{context} Query: {query} Answer:\"\n",
        "\n",
        "    # Generate response using LLM\n",
        "    response = llm.generate_response(system_prompt)\n",
        "\n",
        "    return response\n",
        "\n"
      ],
      "metadata": {
        "id": "kvhUIw8FsO6B"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input questions to gain insights\n"
      ],
      "metadata": {
        "id": "qunAchxot-NZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "\n",
        "# faiss_index = FAISS.load_local(db_faiss_path)\n",
        "faiss_index = faiss.read_index(db_faiss_path)\n",
        "\n",
        "\n",
        "query = \"What is the revenue growth in of Apple in years from 1995-2021.\"\n",
        "query_embedding = generate_embedding(query, model, tokenizer)\n",
        "\n",
        "response = generate_response(query_embedding, llm, faiss_index)\n",
        "print(\"Response:\", response)"
      ],
      "metadata": {
        "id": "oRA_GKdut90T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Different Financial Insights that can be drawn**\n",
        "\n"
      ],
      "metadata": {
        "id": "i9jZ-hPECkID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. AI Financial Filing analysis can be leveraged by small investment firms to enhance research and identifypromising investment opportunities across multiple markets in minutes compared to days. The automated analysis savestime compared to manual review.\n",
        "2. Economists around the world or at institutions can use AI Financial Filing analysis to summarize, understandthe first level of information to get bigger picture of company performance, emerging trends, and risks across industrieseasily. This enables the economists to choose the areas they would like to deep dive to form a more accurate economicforecasting and policy recommendations.\n",
        "3. Banking institutions can use the AI Financial filings analysis to assess lending and credit risks this process willenable them to make more informed decisions around capital allocation.\n",
        "4. Individual investors now have access to professional or institutional-level insights without the need for expertisein finance or Wall Street expertise. The AI levels the playing field for retail investors looking to pick stocks alignedwith their strategy. This also makes it more affordable and democratizes learning of financial analysis.\n",
        "5. Public companies can benchmark against peers, identify improvement opportunities, and stay on top of emerging risks ahead of time based on the AI's broad analysis.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YvH_u3vGCtIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Sample Queries to be put in the model**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qySqmfmDC5Wv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Compare and contrast the customer segments and geographies that grew the fastest in the last 28 years.\n",
        "2. What is the revenue growth in of Apple in years from 1995-2021.\n",
        "3. Compare revenue growth of Apple,Microsoft and Google from 1995 to 2021.\n",
        "4. What are the major consumer products offered by Microsoft?\n",
        "5. Compare stock price per share from year 1995-2021 for Google.\n",
        "6. What is weighted average common shares outstanding for Apple in year 2021?\n",
        "7. How have the investment plans evolved for Microsoft in years from 1995 to 2021?"
      ],
      "metadata": {
        "id": "_Gugqzi8DCkc"
      }
    }
  ]
}